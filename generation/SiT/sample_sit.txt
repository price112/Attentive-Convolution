#!/bin/bash
#SBATCH --job-name=666
#SBATCH --account=project_462001033
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=8
#SBATCH --cpus-per-task=48
#SBATCH --mem=480G
#SBATCH --partition=dev-g
#SBATCH --time=3:00:00

module purge
module load LUMI/24.03 partition/G rocm/6.0.3
export OMP_NUM_THREADS=1

export PATH="/users/conda/torch_old/bin:$PATH"

export NCCL_SOCKET_IFNAME=hsn0,hsn1,hsn2,hsn3
export NCCL_NET_GDR_LEVEL=PHB

export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=29500

srun torchrun \
  --nnodes=$SLURM_JOB_NUM_NODES \
  --nproc_per_node=8 \
  --rdzv_id=\$SLURM_JOB_ID \
  --rdzv_backend=c10d \
  --rdzv_endpoint="$MASTER_ADDR:$MASTER_PORT" \
   sample_ddp.py ODE \
   --model "SiT-B/2-ATConv" \
   --num-fid-samples "50000" \
   --ckpt "" \
   --image-size "512" \
