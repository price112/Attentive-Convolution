#!/bin/bash
#SBATCH --job-name=666
#SBATCH --account=project_462001033
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=8
#SBATCH --cpus-per-task=48
#SBATCH --mem=480G
#SBATCH --partition=standard-g
#SBATCH --time=1-24:00:00

module purge
module load LUMI/24.03 partition/G rocm/6.0.3
export OMP_NUM_THREADS=1

export PATH="/users/conda/torch_old/bin:$PATH"

export NCCL_SOCKET_IFNAME=hsn0,hsn1,hsn2,hsn3
export NCCL_NET_GDR_LEVEL=PHB

export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=29500

export TORCH_HOME=/flash/project_462001033/hao/REPA/.torch
export HF_HOME=/flash/project_462001033/hao/REPA/.hf
mkdir -p "$TORCH_HOME/hub/checkpoints" "$HF_HOME"

srun torchrun \
  --nnodes=$SLURM_JOB_NUM_NODES \
  --nproc_per_node=8 \
  --rdzv_id=\$SLURM_JOB_ID \
  --rdzv_backend=c10d \
  --rdzv_endpoint="$MASTER_ADDR:$MASTER_PORT" \
  train.py \
  --report-to="wandb" \
  --mixed-precision="bf16" \
  --seed=0 \
  --path-type="linear" \
  --prediction="v" \
  --weighting="uniform" \
  --model="SiT-B/2-ATConv" \
  --enc-type="dinov2-vit-b" \
  --proj-coeff=0.5 \
  --encoder-depth=8 \
  --output-dir="sit_atconv" \
  --exp-name="sit_b2_atconv_imgnet_256" \
  --data-dir="../images_256.lmdb" \
  --max-train-steps "2000000" \
  --sampling-steps "10000" \
  --checkpointing-steps "50000" \
